# HW4

### 数据预处理

Code:

```python
# 加载数据集
def load_iris_dataset(filename):
    with open(filename, 'r') as csvfile:
        csvreader = csv.reader(csvfile)
        next(csvreader)  # Skip header if present
        dataset = [list(map(float, row[:-1])) for row in csvreader if row]  # Exclude the label
    return dataset
```

下载uci iris数据集，读取csv内容。

### 实现dbscan算法

Code:

```python
def rangeQuery(X, P, eps):
    distances = euclidean_distances(X[P].reshape(1, -1), X)
    neighbors = set(np.where(distances <= eps)[1].tolist())  # 使用集合存储neighbors
    return neighbors

def dbscan(X, eps, minPts):
    labels = np.full(X.shape[0], -1)
    C = 0
    for P in range(X.shape[0]):
        if labels[P] != -1:
            continue
        neighbors = rangeQuery(X, P, eps)
        if len(neighbors) < minPts:
            labels[P] = -2  # Mark as noise
            continue
        C += 1
        labels[P] = C
        neighbors.remove(P)  # 删除自身，避免后面重复检查
        seeds = neighbors.copy()
        while seeds:
            Pn = seeds.pop()
            if labels[Pn] == -2:
                labels[Pn] = C
            if labels[Pn] == -1:
                labels[Pn] = C
                Pn_neighbors = rangeQuery(X, Pn, eps)
                if len(Pn_neighbors) >= minPts:
                    seeds |= Pn_neighbors  # 使用集合的并集操作添加新的元素
    return labels
```

### `rangeQuery` 函数

- 输入参数
  - `X`是数据点的集合，通常是一个二维数组，其中每一行表示一个数据点。
  - `P`是查询点的索引。
  - `eps`是邻域的半径，表示距离阈值。
- **功能**：该函数用于寻找给定数据点`P`在半径`eps`内的所有邻居。
- 实现细节
  - 首先，计算点`P`到数据集`X`中所有点的欧氏距离。
  - 然后，找出距离小于等于`eps`的点，这些点被认为是`P`的邻居。
  - 返回这些邻居点的索引集合。

### `dbscan` 函数

- - `X`是数据集。
  - `eps`表示两个数据点被认为是邻居的最大距离。
  - `minPts`是形成稠密区域所需的最小邻居数目。
- **功能**：执行DBSCAN算法，对数据集`X`进行聚类。
- 实现细节
  1. 初始化所有点的聚类标签为-1（尚未分类）。
  2. 遍历数据集中的每个点：
     - 如果点已被分类，跳过。
     - 否则，查询其邻居。
     - 如果邻居数量少于`minPts`，则将该点标记为噪声(-2)。
     - 如果邻居数量足够，则创建一个新的簇，将该点及其邻居加入簇中。
  3. 对于每个新找到的邻居点：
     - 如果之前被标记为噪声，现在更改为当前簇的标签。
     - 如果未被分类，也加入当前簇。
     - 如果该邻居点的邻居数量也达到`minPts`，则将其邻居加入到当前考虑的邻居集合中，以此方式扩展簇。
  4. 最终返回所有点的聚类标签。

### 算法时间复杂度与空间复杂度分析

- **时间复杂度**：对于每一个数据点，我们都执行了一次 `rangeQuery`。因此，时间复杂度将是O(n^2)。这是最简单实现版本的时间复杂度，在实际使用中，这个时间复杂度可以通过空间索引数据结构（如KD树，球树等）来优化。
- **空间复杂度**：`dbscan` 函数主要存储了输入数据集和每个点的标签，因此其空间复杂度为O(n)。

### 指标分析

Code:

```python
labels = dbscan(iris, eps=0.2, minPts=5)
end_time=time.time()
print(f'consume time:{end_time-start_time}')
n_clusters = len(set(labels)) - (1 if -1 in labels else 0)
n_noise = list(labels).count(-1)

if n_clusters > 1 and n_noise != len(labels):
    silhouette_avg = silhouette_score(iris, labels)
    print(f"轮廓系数: {silhouette_avg}")
else:
    print("轮廓系数无法计算，需要至少两个簇且不能全部为噪声。")
```

1. `n_clusters = len(set(labels)) - (1 if -1 in labels else 0)`: 计算簇的数量。在`dbscan`执行的结果中，-1代表噪声，其他每个不同的正值代表一个簇。通过生成标签的集合并计算长度，可以得到簇的数量。
2. `n_noise = list(labels).count(-1)`: 计算噪声的数量，也就是标签值为-1的数据点的数量。
3. 接下来，如果生成的簇的数量大于1且噪声的数量不等于数据的总数量，则计算轮廓系数，否则输出提示信息。
   - 轮廓系数是聚类效果的一个度量，其值范围在-1到1之间。越接近1，表示聚类效果越好；越接近-1，表示聚类效果越差。如果所有数据都是噪声或只有一个簇，轮廓系数无法计算。
4. `silhouette_avg = silhouette_score(iris, labels)`: 调用`silhouette_score`函数计算轮廓系数。其中，`iris`是数据集，`labels`是聚类结果。
